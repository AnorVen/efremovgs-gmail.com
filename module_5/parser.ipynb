{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent \n",
    "from bs4 import BeautifulSoup    \n",
    "import requests  \n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Функция по извлечению данных со страницы объявления в словарь data_dict\n",
    "def parsing_page_one_ad(url):\n",
    "\n",
    "    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})    \n",
    "    response.encoding ='utf8'   \n",
    "    \n",
    "    # Теперь создадим объект BeautifulSoup, указывая html парсер    \n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "    data_dict = {}\n",
    "\n",
    "    data_dict['car_url'] = url\n",
    "    data_dict['parsing_unixtime'] = int(time.time())\n",
    "\n",
    "\n",
    "     # в разделах script ищем вхождение 'complectation\":{\"id\"'\n",
    "    for script in page.find_all(\"script\"):\n",
    "        if 'complectation\":{\"id\"' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "    # в a  ищем 'complectation\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n",
    "            data_dict['complectation_dict'] = re.search(r'complectation\":{\"id.*?}', a)[0][15:]\n",
    "\n",
    "        if 'equipment\":{' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "        # в a  ищем 'equipment\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n",
    "            data_dict['equipment_dict'] = re.search(r'equipment\":{.*?}', a)[0][11:]\n",
    "\n",
    "        if '{\"mileage\":' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "        # в a  ищем '{\"mileage\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n",
    "            data_dict['mileage'] = re.search(r'\"mileage\":\\d*', a)[0][10:]\n",
    "\n",
    "        if '\"model_info\":' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "            data_dict['model_info'] = re.search(r'\"model_info\":{.*?}', a)[0][13:]\n",
    "            data_dict['model_name'] = re.search(r'model_info\":{\"code\":\".*?\"', a)[0][20:].strip('\"')\n",
    "\n",
    "        if 'super_gen\":{' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "            data_dict['super_gen'] = re.search(r'super_gen\":{.*?}', a)[0][11:] \n",
    "\n",
    "        if 'vendor\":\"' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "            data_dict['vendor'] = re.search(r'vendor\":\".*?\"', a)[0][9:].strip('\"')\n",
    "\n",
    "\n",
    "    for tag in page.find_all('div'):\n",
    "        if tag.get(\"title\") == \"Идентификатор объявления\":\n",
    "            data_dict['sell_id'] = re.search(r'\\d+', tag.text)[0]\n",
    "\n",
    "\n",
    "    for tag in page.find_all(\"meta\"):\n",
    "        if tag.get(\"itemprop\") == \"bodyType\":\n",
    "            data_dict['bodyType'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"brand\":\n",
    "            data_dict['brand'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"color\":\n",
    "            data_dict['color'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"description\":\n",
    "            data_dict['description'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"engineDisplacement\":\n",
    "            data_dict['engineDisplacement'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"enginePower\":\n",
    "            data_dict['enginePower'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"fuelType\":\n",
    "            data_dict['fuelType'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"modelDate\":\n",
    "            data_dict['modelDate'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"name\":\n",
    "            data_dict['name'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"numberOfDoors\":\n",
    "            data_dict['numberOfDoors'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"price\":\n",
    "            data_dict['price'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"priceCurrency\":\n",
    "            data_dict['priceCurrency'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"productionDate\":\n",
    "            data_dict['productionDate'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"vehicleConfiguration\":\n",
    "            data_dict['vehicleConfiguration'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"vehicleTransmission\":\n",
    "            data_dict['vehicleTransmission'] = tag.get(\"content\")\n",
    "\n",
    "\n",
    "    span_CardInfoRow__cell = page.find_all('span', {'class': 'CardInfoRow__cell'})\n",
    "\n",
    "    for i,tag in enumerate (span_CardInfoRow__cell):\n",
    "        if tag.text == \"Владельцы\":\n",
    "            data_dict['Владельцы'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n",
    "\n",
    "        if tag.text == \"Владение\":\n",
    "            data_dict['Владение'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел    \n",
    "\n",
    "        if tag.text == \"ПТС\":\n",
    "            data_dict['ПТС'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел    \n",
    "\n",
    "        if tag.text == \"Привод\":\n",
    "            data_dict['Привод'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел \n",
    "\n",
    "        if tag.text == \"Руль\":\n",
    "            data_dict['Руль'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n",
    "\n",
    "        if tag.text == \"Состояние\":\n",
    "            data_dict['Состояние'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел \n",
    "\n",
    "        if tag.text == \"Таможня\":\n",
    "            data_dict['Таможня'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "    \n",
    "# Функция по созданию списка ссылок links_list  на объявления о продаже автомобилей  \n",
    "def extraction_links(url):\n",
    "    links_list =[] \n",
    "    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})  \n",
    "    response.encoding ='utf8'\n",
    "    page = BeautifulSoup(response.text, 'html.parser') \n",
    "    links = page.find_all('a', class_='Link ListingItemTitle-module__link')\n",
    "    \n",
    "    for link in links:\n",
    "        links_list.append(link.get(\"href\"))\n",
    "    return links_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "df = pd.DataFrame() # инициализируем итоговый датафрейм \n",
    "\n",
    "url_link_list = [] # список страниц по годам и номерам от 1 до 99\n",
    "\n",
    "ranges = [range(1981, 2006), range(1, 100)] # указываем года и диапазон страниц, которые будем парсить \n",
    "\n",
    "# index[0] - year, index[1] - page \n",
    "for index in itertools.product(*ranges):\n",
    "    # формируем ссылки страницы со списками объявлений\n",
    "    url_links  = (f\"https://auto.ru/moskva/cars/{index[0]}-year/all/?output_type=table&page={index[1]}\")\n",
    "    url_link_list.append(url_links) # заносим их в список\n",
    "    \n",
    "links_list = [] # список списков ссылок на объявления c одной страницы таблицы объявлений\n",
    "\n",
    "#for url_links in url_link_list:\n",
    "# извлекаем в links_list список ссылок на объявления\n",
    "try:\n",
    "        #links_list = extraction_links(url_links)\n",
    "    links_list = Parallel(n_jobs = 2)(delayed(extraction_links)(url_links) for url_links in url_link_list)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "ads_dict_list = [] # список словарей содержимого объявлений\n",
    "\n",
    "for links in links_list:\n",
    "    try:\n",
    "        ads_dict_list = Parallel(n_jobs = 2)(delayed(parsing_page_one_ad)(ad_url) for ad_url in links)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for ad in ads_dict_list:\n",
    "        try:\n",
    "            df = df.append(ad, ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "df.to_csv('_auto_ru_2081-2006.csv', encoding = 'utf-8', index=False) # записываем содержимое датафрейма в файл"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
